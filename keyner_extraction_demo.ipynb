{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting relevant NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from functools import partial\n",
    "\n",
    "from backend.keyword.extraction import KeywordExtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theory behind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Представляется, что мы можем судить о важности слова исходя из сравнения распределения его частотности по документам.\n",
    "Проще говоря, если токен является ключевым для какого-то подкорпуса, то его встречаемость в этом подкорпусе будет\n",
    "сильно отличаться от его обычной встречаемости. И наоборот - если слово не является каким-то детерминирующим, то его \n",
    "встречаемость в подкорпусе будет примерно такой же, как и везде.\n",
    "\n",
    "$H_0:$ частотность слова $t$ в подкорусе $d$ статистически значимо превышает его частотность в документах из коллекции $D$\n",
    "\n",
    "$H_1:$ частотность слова $t$ в подкорусе $d$ не превышает его частотность в документах из коллекции $D$\n",
    "\t\n",
    "Нас интересуют следующие значения:\n",
    "\n",
    "|    | d | D |\n",
    "|----| ------| --- |\n",
    "| t  | j | k |\n",
    "| ~t | l | m |\n",
    "\n",
    "* $j$ - количество вхождений слова $t$ в подкорус $d$ \n",
    "* $k$ - количество вхождений слова $t$ во все тексты коллекции $D$\n",
    "* $l$ - количество вхождений всех слов, кроме $t$, в подкорус $d$ \n",
    "* $m$ - количество вхождений всех слов, кроме $t$, в коллекцию документов $D$\n",
    "\n",
    "**Ожидаемая** частотность слова $t$ в документе $d$ рассчитывается следующим образом: \n",
    "\n",
    "$$Expected = \\frac{( j + k ) \\times (j + l)}{j + k + l + m}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы понять, *достаточно ли сильно* ожидаемая частотность превышает наблюдаемую, необходимо воспользоваться статистическим критерием.\n",
    "Для сравнения распределений хорошо подходит $\\chi^2$ (хи-квадрат). Посчитать его можно по следующей сокращенной формуле:\n",
    "\n",
    "$$\\chi^2 = \\frac{(observed - expected)^2}{expected}$$\n",
    "\n",
    "При этом за наблюдаемую (observed) частотность мы принимаем то, сколько раз слово встретилось в анализируемом подкорпусе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Статистически значимыми словами считаются те, для которых значение $\\chi^2$ превышает некое критическое значение. \n",
    "\n",
    "При этом выбор критического значения зависит от того, насколько мы готовы принять риск не распознать действительно важные слова как таковые. \n",
    "Проще говоря, чем выше критическое значение, тем с большей вероятностью мы упустим некоторые из ключевых слов. Но брать слишком \n",
    "низкие критические значения тоже чревато: в этом случае растет риск назвать ключевыми те слова, которые ими не являются.  \n",
    "\n",
    "Вероятность назвать неключевое слово ключевым называется уровнем значимости.\n",
    "Ниже представлен словарь с критическими значениями для разных уровней значимости: \n",
    "`CRITERION = {0.05: 3.842, 0.01: 6.635, 0.001: 10.828}`\n",
    "Здесь ключи - это уровень значимости, а значение - критическая точка хи-квадрат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ссылка на оригинальную статью: https://cyberleninka.ru/article/n/raspredelenie-hi-kvadrat-i-vzveshivanie-terminov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_DIR = 'data'\n",
    "\n",
    "all_datasets = datasets.load_dataset('tner/tweetner7', cache_dir=CACHE_DIR)\n",
    "train_dataset = all_datasets['train_all']\n",
    "\n",
    "label_2_id = {\n",
    "                 \"B-corporation\": 0,\n",
    "                 \"B-creative_work\": 1,\n",
    "                 \"B-event\": 2,\n",
    "                 \"B-group\": 3,\n",
    "                 \"B-location\": 4,\n",
    "                 \"B-person\": 5,\n",
    "                 \"B-product\": 6,\n",
    "                 \"I-corporation\": 7,\n",
    "                 \"I-creative_work\": 8,\n",
    "                 \"I-event\": 9,\n",
    "                 \"I-group\": 10,\n",
    "                 \"I-location\": 11,\n",
    "                 \"I-person\": 12,\n",
    "                 \"I-product\": 13,\n",
    "                 \"O\": 14\n",
    "             }\n",
    "id_2_label = {v: k for k, v in label_2_id.items()}\n",
    "\n",
    "def to_bio(row, labels_mapping: dict):\n",
    "    bio_labels = []\n",
    "    for label in row['tags']:\n",
    "        bio_labels.append(labels_mapping[label])\n",
    "    row['bio_labels'] = bio_labels\n",
    "    return row\n",
    "\n",
    "converter_fn = partial(to_bio, labels_mapping={v: k for k, v in label_2_id.items()})\n",
    "train_df = pd.DataFrame(train_dataset.map(converter_fn))[['tokens', 'date', 'bio_labels']]\n",
    "train_df[\"date\"] = pd.to_datetime(train_df.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>date</th>\n",
       "      <th>bio_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Morning, 5km, run, with, {{USERNAME}}, for, b...</td>\n",
       "      <td>2019-10-13</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, B-event, O, B-e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[President, Trump, Arrives, at, UFC, 244, in, ...</td>\n",
       "      <td>2019-11-03</td>\n",
       "      <td>[B-person, I-person, O, O, B-corporation, I-co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[\", I, 've, been, in, law, enforcement, for, 2...</td>\n",
       "      <td>2020-05-31</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[I, got, mine, yesterday, !, ****, Doctors, sa...</td>\n",
       "      <td>2019-10-06</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Mayo, Breast, Cancer, Vaccine, Could, Be, Ava...</td>\n",
       "      <td>2019-10-13</td>\n",
       "      <td>[B-product, I-product, I-product, I-product, O...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens       date  \\\n",
       "0  [Morning, 5km, run, with, {{USERNAME}}, for, b... 2019-10-13   \n",
       "1  [President, Trump, Arrives, at, UFC, 244, in, ... 2019-11-03   \n",
       "2  [\", I, 've, been, in, law, enforcement, for, 2... 2020-05-31   \n",
       "3  [I, got, mine, yesterday, !, ****, Doctors, sa... 2019-10-06   \n",
       "4  [Mayo, Breast, Cancer, Vaccine, Could, Be, Ava... 2019-10-13   \n",
       "\n",
       "                                          bio_labels  \n",
       "0  [O, O, O, O, O, O, O, O, O, O, B-event, O, B-e...  \n",
       "1  [B-person, I-person, O, O, B-corporation, I-co...  \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "3  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "4  [B-product, I-product, I-product, I-product, O...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define period of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "start, end = '2019-10-10', '2019-10-20'\n",
    "x = datetime.datetime(*list(map(int, start.split('-'))))\n",
    "y = datetime.datetime(*list(map(int, end.split('-'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can extract relevant NER along with their category and relevance score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = KeywordExtractor(data=train_df)\n",
    "relevant_ner = extractor.extract_relevant(start=x, end=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>score</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Breaking Bad</td>\n",
       "      <td>53.828056</td>\n",
       "      <td>creative_work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{@YouTube@}</td>\n",
       "      <td>52.824189</td>\n",
       "      <td>product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>El Camino</td>\n",
       "      <td>22.664445</td>\n",
       "      <td>creative_work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{@Aaron Paul@}</td>\n",
       "      <td>14.165278</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ElCamino</td>\n",
       "      <td>11.332222</td>\n",
       "      <td>creative_work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{@Breaking Bad@}</td>\n",
       "      <td>11.332222</td>\n",
       "      <td>creative_work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Seahawks</td>\n",
       "      <td>10.786720</td>\n",
       "      <td>group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{@Poshmark@}</td>\n",
       "      <td>9.567815</td>\n",
       "      <td>product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BreakingBad</td>\n",
       "      <td>8.499167</td>\n",
       "      <td>creative_work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bra</td>\n",
       "      <td>8.499167</td>\n",
       "      <td>product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             entity      score       category\n",
       "0      Breaking Bad  53.828056  creative_work\n",
       "1       {@YouTube@}  52.824189        product\n",
       "2         El Camino  22.664445  creative_work\n",
       "3    {@Aaron Paul@}  14.165278         person\n",
       "4          ElCamino  11.332222  creative_work\n",
       "5  {@Breaking Bad@}  11.332222  creative_work\n",
       "6          Seahawks  10.786720          group\n",
       "7      {@Poshmark@}   9.567815        product\n",
       "8       BreakingBad   8.499167  creative_work\n",
       "9               bra   8.499167        product"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(relevant_ner)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
